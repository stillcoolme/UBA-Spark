## 用户活跃度
交互式用户行为分析就是要在页面快速得出分析结果，与离线分析相对。
为什么用Spark RDD API来开发这些复杂的业务逻辑，为什么不直接用SQL？
用SQL是可以的，但SQL主要适用于大量离线批处理的ETL作业和统计分析报表逻辑（统计分析报表需求灵活，多变）。

但是我们这个是一套系统，和java web配合的系统，模块和需求都是固定的。
用SQL的缺点在于，Spark底层自动生成执行计划和代码，我们几乎无法进行深度的调优，遇到问题也不好解决。
包括参数调优以及数据倾斜的重构和优化等等，遇到报错，都是最底层的源码，我们可以进行定位和修复问题。

但是现在spark2.x中 spark sql的各种内嵌的性能优化是比人裸写RDD遵守各种所谓的最佳实践更靠谱的，尤其对新手来讲。
比如有些最佳实践讲到先filter操作再 map 操作，这种spark sql中会自动进行谓词下推，
比如尽量避免使用 shuffle 操作，spark sql 中如果你开启了相关的配置，会自动使用 broadcast join 来广播小表，把 shuffle join 转化为 map join 等等，真的能让我们省很多心。

### 用户活跃度分析需求

1. 指定时间段内访问次数最多的10个用户。
2. 指定时间段内购买商品金额最多的10个用户。
3. 最近周期内相对之前一个周期访问次数增长最快的10个用户。
      * 需求详细：设定一个周期是1个月，有1个用户，在9月份这个周期内总共访问了100次，在10月份这个周期内总共访问了200次。
          则该用户在最近一个周期相比上一个周期，访问次数增长了100次。
          每个用户都可以计算出这么一个值，获取到最近两个周期内，访问次数增长最多的10个用户。
          周期，是可以由用户在web界面上填写的，java web系统会写入mysql，我们可以去获取本次执行的周期。
      * 解决思路：上一周期的每次访问设为 -1， 现在的这一周期的每次访问设为 +1。
          然后相同用户的相加，就得到这一周期的用户访问相比上一周期多出多少次。
4. 最近周期内相对之前一个周期购买商品金额增长最快的10个用户。
      * 和需求3基本相同，注意聚合钱数的时候用round来取小数前两位。
5. 指定周期内注册的新用户在头7天访问次数最多的10个用户。
